# -*- coding: utf-8 -*-
"""Cloning Shazam App.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VneVfgZaN1aECoTQ5pM94TdH-1_4CWIZ
"""

!pip install streamlit faiss-cpu assemblyai sentence-transformers pysqlite3-binary pandas numpy

import os
import json
import numpy as np
import streamlit as st
import faiss
import assemblyai as aai
import sqlite3
from sentence_transformers import SentenceTransformer
import pandas as pd
import tempfile

!pip install pyngrok

from google.colab import drive
drive.mount('/content/drive')

# Load AssemblyAI API key
aai.settings.api_key = "db505a784a0d4dc093f0bee4121c1f82"

# Load Subtitle Database
DB_PATH = "/content/drive/MyDrive/eng_subtitles_database.db"

# Load Pre-trained Sentence Transformer Model
model = SentenceTransformer("all-MiniLM-L6-v2")

def load_subtitles(db_path):
    conn = sqlite3.connect(db_path)
    df = pd.read_sql("SELECT num, name, content FROM zipfiles", conn)
    conn.close()

    # Convert binary content to text
    df["decoded_text"] = df["content"].apply(lambda x: x.decode("latin-1") if isinstance(x, bytes) else "")

    return df

#  Load Subtitle Embeddings and Create FAISS Index
def create_faiss_index(df):

    embeddings = model.encode(df["decoded_text"].tolist(), show_progress_bar=True)
    embeddings = np.array(embeddings)

    # Initialize FAISS Index
    d = embeddings.shape[1]  # Embedding Dimension
    index = faiss.IndexFlatL2(d)
    index.add(embeddings)  # Add embeddings to FAISS

    return index, df

# Transcribe Audio with AssemblyAI
def transcribe_audio(audio_path):
    """ Convert speech to text using AssemblyAI """
    transcriber = aai.Transcriber()
    transcript = transcriber.transcribe(audio_path)
    return transcript.text

# Search Subtitles Using FAISS
def search_subtitles(query_text, index, df, top_k=5):
    """ Find the most relevant subtitle segments for the given query """
    query_embedding = model.encode([query_text])
    D, I = index.search(query_embedding, top_k)  # FAISS similarity search
    results = df.iloc[I[0]]
    return results

# Streamlit
st.set_page_config(page_title="Shazam Clone: Audio-to-Subtitle Search", layout="wide")

# Title
st.title("🎵 Shazam Clone: Audio-to-Subtitle Search")
st.markdown("Upload an **audio file**, transcribe it to text, and retrieve the most relevant subtitle segments!")

with st.spinner("Loading subtitle database..."):
    df = load_subtitles(DB_PATH)
    index, df = create_faiss_index(df)

# 🔹 File Upload Section
uploaded_file = st.file_uploader("🎤 Upload an audio file", type=["mp3", "wav", "m4a"])

if uploaded_file:
    st.audio(uploaded_file, format="audio/mp3")

    #  Transcription
    if st.button("🎙 Transcribe Audio"):
        with st.spinner("Transcribing... This may take a moment..."):
            query_text = transcribe_audio(uploaded_file)
            st.success("✅ Transcription Complete!")
            st.text_area("🎧 Transcribed Text", query_text, height=150)

            #  Search in FAISS
            with st.spinner("Searching relevant subtitles..."):
                results = search_subtitles(query_text, index, df)

                #  Display Search Results
                st.markdown("## 🔍 **Top Matching Subtitles**")
                for i, row in results.iterrows():
                    st.markdown(f"""
                    **🎬 Movie:** {row["name"]}
                    - **📜 Subtitle:** `{row["decoded_text"]}`
                    - 🔗 **[View on OpenSubtitles](https://www.opensubtitles.org/en/subtitles/{row["num"]})**
                    """)

# 🎨 Sidebar Styling
st.sidebar.header("🔧 Settings")
st.sidebar.markdown("""
- **Powered by:** `FAISS + AssemblyAI + Sentence Transformers`
- **Database:** `SQLite (.db) file`
- **Search Mechanism:** `Semantic Search (FAISS)`
""")

st.sidebar.write("📌 Built with ❤️ using **Streamlit** 🚀")

# starts streamlit
if __name__ == '__main__':
    st.run()

from pyngrok import ngrok

public_url = ngrok.connect(port=8501)
print("Streamlit App URL:", public_url)
!Cloning Shazam App.py